from typing import List

import torch
import torch.nn as nn
from tqdm import tqdm


def reconstruction_training(
    data: list,
    epochs: int,
    encoder: nn.Module,
    encoder_optim: torch.optim.Optimizer,
    decoder: nn.Module,
    decoder_optim: torch.optim.Optimizer,
    loss_fn: nn.Module,
    noise_std: float = 0.0,
    logger=None,
    contrastive: bool = False,
):
    """Trains an encoder-decoder pair for reconstruction"""
    # initialise loss tracker
    losses = []

    # clarification: one epoch = one pass over complete dataset
    for e in tqdm(range(epochs)):

        t_loss = 0

        for x in data:

            if noise_std != 0.0:
                input_noise = torch.randn_like(x) * (noise_std / 10)
            else:
                input_noise = 0.0

            y = x + input_noise
            y = encoder(y)
            y += (torch.randn_like(y) * noise_std) if noise_std != 0.0 else 0.0
            y = decoder(y)
            loss = loss_fn(y, x)

            if contrastive:
                pass

            for o in [decoder_optim, encoder_optim]:
                if o is not None:
                    o.zero_grad()

            loss.backward()

            for o in [decoder_optim, encoder_optim]:
                if o is not None:
                    o.step()

            t_loss += loss.item()

        if logger is not None:
            logger.log({"epoch": e, "loss/reconstruction": t_loss})

        losses.append(t_loss)

    return losses, encoder, decoder



def multi_reconstruction_training(
    data: list,
    epochs: int,
    encoder: nn.Module,
    encoder_optim: torch.optim.Optimizer,
    decoders: List[nn.Module],
    decoder_optims: List[torch.optim.Optimizer],
    loss_fns: List[nn.Module],
    loss_weights: List[float],
    noise_std: float = 0.0,
    logger=None,
    contrastive: bool = False,
):
    """Trains an encoder and set of decoder for multiple reconstructions"""
    # initialise loss tracker
    losses = []

    # clarification: one epoch = one pass over complete dataset
    for e in tqdm(range(epochs)):

        t_loss = 0

        for i, (x, ys) in enumerate(data):

            if noise_std != 0.0:
                input_noise = torch.randn_like(x) * noise_std
            else:
                input_noise = 0.0

            r = x + input_noise
            r = encoder(r)
            # r += (torch.randn_like(r) * noise_std) if noise_std != 0.0 else 0.0
            rs = [decoder(r) for decoder in decoders]
            loss = sum([w*loss_fn(r, y) for w, loss_fn, r, y in zip(loss_weights, loss_fns, rs, ys)])

            if contrastive:
                pass

            for o in [encoder_optim] + decoder_optims:
                if o is not None:
                    o.zero_grad()

            loss.backward()

            for o in [encoder_optim] + decoder_optims:
                if o is not None:
                    o.step()

            t_loss += loss.item()

        if logger is not None:
            logger.log({"epoch": e, "loss/reconstruction": t_loss})

        losses.append(t_loss)

    return losses, encoder, decoders


def target_training(
    xs: torch.utils.data.DataLoader,
    ys: torch.utils.data.DataLoader,
    epochs: int,
    net: nn.Module,
    net_optim: torch.optim.Optimizer,
    loss_fn: nn.Module,
    noise_std: float = 0.0,
    logger=None,
):
    """Trains an a networks with x, y pairs for f(x) = y"""
    assert len(xs) == len(ys)

    # initialise loss tracker
    losses = []

    # clarification: one epoch = one pass over complete dataset
    for e in tqdm(range(epochs)):

        t_loss = 0

        # iterate over transforms, training one at a time data that encapsulates
        # its behavior (generated by actually applying the trasforms classically)
        for i, (x, y) in enumerate(zip(xs, ys)):

            pred = net(x)
            if noise_std != 0.0:
                pred += torch.randn_like(pred) * noise_std
            loss = loss_fn(y, pred)

            net_optim.zero_grad()

            loss.backward()

            if logger is not None:
                logger.log({i: loss.item()})

            t_loss += loss.item()

            net_optim.step()

        if logger is not None:
            logger.log({"epoch": e, "loss/reconstruction": t_loss / (i+1)})

        losses.append(t_loss / (i+1))

    return losses, net


def train_transform(
    data: torch.utils.data.DataLoader,
    epochs: int,
    encoder: nn.Module,
    encoder_optim: torch.optim.Optimizer,
    decoder: nn.Module,
    decoder_optim: torch.optim.Optimizer,
    transform: nn.Module,
    tf_optim: torch.optim.Optimizer,
    loss_fn: nn.Module,
    noise_std: float = 0.0,
    tf_name: str = None,
    logger=None,
):
    """Trains an encoder-decoder pair and a set of transforms."""
    assert not (encoder_optim is None and decoder_optim is None and tf_optim is None)
    assert logger is None or (
        logger is not None and tf_name is not None
    ), "tf_name must be specified if logger is specified"

    # initialise loss tracker
    losses = []
    n = len(data)

    # clarification: one epoch = one pass over complete dataset
    for e in tqdm(range(epochs)):

        t_loss = 0

        for x, y in data:

            # if noise_std != 0.0:
                # x += torch.randn_like(x) * (noise_std / 10)
            x = encoder(x)
            if noise_std != 0.0:
                x += torch.randn_like(x) * noise_std
            x = transform(x)
            # if noise_std != 0.0:
                # x += torch.randn_like(x) * noise_std
            x = decoder(x)

            loss = loss_fn(x, y)

            if tf_optim is not None:
                tf_optim.zero_grad()
            for o in [encoder_optim, decoder_optim]:
                if o is not None:
                    o.zero_grad()

            loss.backward()

            t_loss += loss.item()

            if tf_optim is not None:
                tf_optim.step()
            for o in [encoder_optim, decoder_optim]:
                if o is not None:
                    o.step()

        if logger is not None:
            logger.log({"epoch": e, f"loss/{tf_name}": t_loss / n})
        losses.append(t_loss / n)

    return losses, encoder, decoder, transform


def train_transforms_sequences(
    data: dict,
    epochs: int,
    encoder: nn.Module,
    encoder_optim: torch.optim.Optimizer,
    decoder: nn.Module,
    decoder_optim: torch.optim.Optimizer,
    transforms: dict,
    tf_optims: dict,
    loss_fn: nn.Module,
    noise_std: float = 0.0,
    logger=None,
):
    """Trains an encoder-decoder pair and a set of transforms."""
    assert not (encoder_optim is None and decoder_optim is None and tf_optims is None)

    # initialise loss tracker
    losses = []

    # clarification: one epoch = one pass over complete dataset
    for e in tqdm(range(epochs)):

        t_loss = 0
        n = 0

        # iterate over transforms, training one at a time data that encapsulates
        # its behavior (generated by actually applying the trasforms classically)
        for i, (tf_seq, tf_mask, io_pairs) in enumerate(data):
            tf_net_optims = (
                None
                if tf_optims is None
                else [
                    tf_optims[tf_seq[k]] if tf_mask[k] else None
                    for k in range(len(tf_seq))
                ]
            )

            inputs, outputs = zip(*io_pairs)
            x = torch.cat(inputs, dim=0)
            y = torch.cat(outputs, dim=0)

            x = encoder(x)
            if noise_std != 0.0:
                x += torch.randn_like(x) * noise_std
            for tf_name in tf_seq:
                x = transforms[tf_name](x)
            if noise_std != 0.0:
                x += torch.randn_like(x) * noise_std
            x = decoder(x)

            loss = loss_fn(x, y)

            for tf_net_optim in tf_net_optims:
                if tf_net_optim is not None:
                    tf_net_optim.zero_grad()
            for o in [encoder_optim, decoder_optim]:
                if o is not None:
                    o.zero_grad()

            loss.backward()

            if logger is not None:
                logger.log({i: loss.item()})

            t_loss += loss.item()
            n += 1

            for tf_net_optim in tf_net_optims:
                if tf_net_optim is not None:
                    tf_net_optim.step()
            for o in [encoder_optim, decoder_optim]:
                if o is not None:
                    o.step()

        losses.append(t_loss / n)

    return losses, encoder, decoder, transforms


def train_neural_model(
    data,
    model,
    model_optim,
    io_embedding,
    io_embedding_optim,
    epochs,
    program_embedding,
    io_encoder,
    loss_fn,
):
    losses = []

    for e in tqdm(range(epochs)):
        loss = 0.0

        for d in data:
            i, o = [io_embedding(io_encoder(d[j])) for j in ["input", "output"]]
            p = program_embedding(d["program"])
            d_loss = sum(
                [
                    loss_fn(model([p[:c]], [i, o]), p[c].unsqueeze(0))
                    for c in range(len(p))
                ]
            )
            if model_optim is not None:
                model_optim.zero_grad()
            if io_embedding_optim is not None:
                io_embedding_optim.zero_grad()
            d_loss.backward()
            if model_optim is not None:
                model_optim.step()
            if io_embedding_optim is not None:
                io_embedding_optim.step()

            loss += d_loss.item()

        losses.append(loss)

    return losses


if __name__ == "__main__":
    import pickle

    import dill
    import matplotlib.pyplot as plt
    import numpy as np
    import torch.nn.functional as F

    from models import create_mlp
    from ohe import ohe_fns_creator

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dtype = torch.float

    shapes = ["circle", "square", "triangle", "delta"]
    (
        data_split,
        one_hot_mapping,
        one_hot_represent,
        ohe_decode,
        single_object_ohe_hit_check,
        ohe_hit_check,
        ohe_partial_hit_check,
        ohe_loss_fn_creator,
        one_hot_tensor_represent_creator,
    ) = ohe_fns_creator(shapes, 3)

    ohe_loss_fn = ohe_loss_fn_creator()
    one_hot_tensor_represent = one_hot_tensor_represent_creator(device, dtype)

    boards = pickle.load(open("data/boards/boards_upto_3.pkl", "rb"))
    lib = dill.load(open("data/libraries/library0.pkl", "rb"))

    input_dim = sum(data_split)
    latent_dim = 32

    # instantiate nets
    simple_encoder = create_mlp(input_dim, latent_dim, [16]).to(dtype).to(device)
    simple_decoder = create_mlp(latent_dim, input_dim, [16]).to(dtype).to(device)
    simple_transforms = {
        k: create_mlp(latent_dim, latent_dim, [32]).to(dtype).to(device)
        for k in lib.primitives_dict.keys()
    }

    # learning rates
    encoder_lr = 3e-4
    decoder_lr = 3e-4
    tf_lr = 3e-4

    # instatiate optimizers
    simple_encoder_optim = torch.optim.Adam(simple_encoder.parameters(), lr=encoder_lr)
    simple_decoder_optim = torch.optim.Adam(simple_decoder.parameters(), lr=decoder_lr)
    simple_tf_optims = {
        k: torch.optim.Adam(tf_net.parameters(), lr=tf_lr)
        for k, tf_net in simple_transforms.items()
    }

    # training
    reconstruction_training_data = torch.utils.data.DataLoader(
        [
            (
                one_hot_tensor_represent(b)[0].squeeze(0),
                (one_hot_tensor_represent(b)[0].squeeze(0),),
            )
            for b in boards[0]
        ],
        batch_size=36,
    )

    losses = reconstruction_training(
        reconstruction_training_data,
        1000,
        simple_encoder,
        simple_encoder_optim,
        [simple_decoder],
        [simple_decoder_optim],
        loss_fns=[ohe_loss_fn_creator()],
        loss_coefficients=[1.0],
        noise_std=2.0,
        logger=None,
    )

    plt.plot(losses)
    plt.show()

    all_tf_training_data = {
        tf: torch.utils.data.DataLoader(
            [
                (
                    one_hot_tensor_represent(i)[0].squeeze(0),
                    one_hot_tensor_represent(lib.apply_program([tf, "out"], i))[
                        0
                    ].squeeze(0),
                )
                for i in boards[0]
            ],
            batch_size=36,
        )
        for tf in simple_transforms.keys()
    }

    print(all_tf_training_data)

    num_epochs = 1000
    losses = np.zeros((num_epochs,))
    for tf, tf_training_data in all_tf_training_data.items():

        t_losses = train_transform(
            tf_training_data,
            num_epochs,
            simple_encoder,
            None,
            simple_decoder,
            None,
            simple_transforms[tf],
            simple_tf_optims[tf],
            loss_fn=F.mse_loss,
            noise_std=2.0,
            logger=None,
        )
        losses += t_losses

    losses /= len(simple_transforms)
    plt.plot(losses)
    plt.show()
