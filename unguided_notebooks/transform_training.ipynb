{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transform_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FuvN8Ik9wRU",
        "outputId": "507ad4ac-0095-4adf-d7c5-3bf2651d0639"
      },
      "source": [
        "!git clone https://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@github.com/threewisemonkeys-as/nar.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nar'...\n",
            "remote: Enumerating objects: 9172, done.\u001b[K\n",
            "remote: Counting objects: 100% (9095/9095), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8988/8988), done.\u001b[K\n",
            "remote: Total 9172 (delta 155), reused 9042 (delta 105), pack-reused 77\u001b[K\n",
            "Receiving objects: 100% (9172/9172), 80.35 MiB | 14.55 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgFgSwHD-3LP",
        "outputId": "736775ab-397b-49bd-aa48-28efb99e20df"
      },
      "source": [
        "%cd nar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZM1Xfg_G3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f70152-52f7-4fdd-e36f-f9747a193969"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.11.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.62.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.10.0+cu111)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.13)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.3.4)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.70.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 8)) (3.10.0.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (5.4.8)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (2.23.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (3.17.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r requirements.txt (line 11)) (1.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->-r requirements.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->-r requirements.txt (line 6)) (3.7.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=e06dd46750aa1d8c6c57aba46ee1a962f387023f689bf4f8135cfb4959ef3bba\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=b51ecf8844be737f3e280d6576f7e0a932c8c3c9c479697898fc607e5603d699\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.26 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.2 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmywBi2WjQQo"
      },
      "source": [
        "import copy\n",
        "import itertools\n",
        "import pathlib\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import dill\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocess as mp\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from src.datagen import (\n",
        "    generate_board_states,\n",
        "    # generate_examples_exhaustive,\n",
        "    # generate_examples_random,\n",
        ")\n",
        "from src.ohe import ohe_fns_creator\n",
        "from src.image import draw_board, load_shape_map\n",
        "from src.library import Library,Primitive,AffineTransform,to_shape_creator,shift_creator,flip\n",
        "from src.datagen import BOARD_SIZE\n",
        "#########################################\n",
        "### Set up seeds, logging and devices ###\n",
        "#########################################\n",
        "\n",
        "from itertools import product\n",
        "def add_rotations(shapes,angles=[0,90,180,270]):\n",
        "  ans=[]\n",
        "  for shape,angle in product(shapes,angles):\n",
        "    ans.append(\"%d%s\" %(angle,shape))\n",
        "  return ans\n",
        "\n",
        "def add_affine(shapes,x,y,maintain_og=True):\n",
        "  ans=[]\n",
        "  for shape in shapes:\n",
        "    ans.append(shape+str(x)+str(y))\n",
        "  if not maintain_og:\n",
        "    return ans\n",
        "  return ans+shapes\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cpu\" if (not torch.cuda.is_available()) else \"cuda\")\n",
        "dtype = torch.float\n",
        "\n",
        "#################################\n",
        "### Set up the model and data ###\n",
        "#################################\n",
        "unseen_shapes_easy = add_rotations([\"k\",\"u\"])\n",
        "unseen_shapes_hard = add_rotations([\"psi\",\"w\"])\n",
        "unseen_shapes=unseen_shapes_easy+unseen_shapes_hard\n",
        "seen_shapes = add_rotations([\"circle\", \"square\", \"triangle\", \"delta\", \"b\", \"d\", \"e\", \"g\", \"m\", \"r\", \"s\", \"x\", \"z\", \"theta\", \"pi\", \"tau\"])\n",
        "\n",
        "affine_x=5\n",
        "affine_y=5\n",
        "\n",
        "shapes1=add_affine(unseen_shapes_easy+seen_shapes+unseen_shapes_hard,affine_x,affine_y)\n",
        "shapes2=add_affine(unseen_shapes_easy+seen_shapes+unseen_shapes_hard,-5,-5,maintain_og=False)\n",
        "shapes=shapes1+shapes2\n",
        "seen_boards = generate_board_states(seen_shapes, 1)\n",
        "unseen_boards_easy = generate_board_states(unseen_shapes,1)\n",
        "(\n",
        "    data_split,\n",
        "    one_hot_mapping,\n",
        "    one_hot_represent,\n",
        "    ohe_decode,\n",
        "    single_object_ohe_hit_check,\n",
        "    ohe_hit_check,\n",
        "    ohe_partial_hit_check,\n",
        "    ohe_loss_fn_creator,\n",
        "    one_hot_tensor_represent_creator,\n",
        ") = ohe_fns_creator(shapes, 3)\n",
        "one_hot_tensor_represent = one_hot_tensor_represent_creator(device, dtype)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5opAHs_skAj"
      },
      "source": [
        "lib = Library(\n",
        "        [\n",
        "            to_shape_creator(\"square\",0),\n",
        "            to_shape_creator(\"circle\",0),\n",
        "            to_shape_creator(\"triangle\",0),\n",
        "            to_shape_creator(\"delta\",0),\n",
        "            AffineTransform(\"affine+\",5,5),\n",
        "            AffineTransform(\"affine-\",-5,-5),\n",
        "            *shift_creator(BOARD_SIZE),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYSTWE27LMq_"
      },
      "source": [
        "trans_images = pickle.load(open('data/trans_images.pickle','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpU071iVVRaD"
      },
      "source": [
        "affine_seen_shapes_plus=[]\n",
        "affine_unseen_shapes_plus=[]\n",
        "for key in trans_images:\n",
        "  if (key[1]==(5,5)) and key[0] in seen_shapes:\n",
        "    affine_seen_shapes_plus.append(key[0])\n",
        "  elif (key[1]==(5,5)) and key[0] in unseen_shapes_easy+unseen_shapes_hard:\n",
        "    affine_unseen_shapes_plus.append(key[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHsYAhxmaoDI"
      },
      "source": [
        "affine_seen_shapes_minus=[]\n",
        "affine_unseen_shapes_minus=[]\n",
        "for key in trans_images:\n",
        "  if (key[1]==(-5,-5)) and key[0] in seen_shapes:\n",
        "    affine_seen_shapes_minus.append(key[0])\n",
        "  elif (key[1]==(-5,-5)) and key[0] in unseen_shapes_easy+unseen_shapes_hard:\n",
        "    affine_unseen_shapes_minus.append(key[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVUNZXjgUroH"
      },
      "source": [
        "def add_affine(shapes,x,y):\n",
        "  ans=[]\n",
        "  for shape in shapes:\n",
        "    ans.append(shape+str(x)+str(y))\n",
        "  return ans+shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQyYLrz7cGQQ"
      },
      "source": [
        "affine_seen_shapes_minus=add_affine(affine_seen_shapes_minus,-5,-5)\n",
        "affine_seen_shapes_plus=add_affine(affine_seen_shapes_plus,5,5)\n",
        "affine_unseen_shapes_minus=add_affine(affine_unseen_shapes_minus,-5,-5)\n",
        "affine_unseen_shapes_plus=add_affine(affine_unseen_shapes_plus,5,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9NFIGxhtgje"
      },
      "source": [
        "seen_boards_affine_plus = generate_board_states(affine_seen_shapes_plus, 1)\n",
        "unseen_boards_affine_plus = generate_board_states(affine_unseen_shapes_plus,1)\n",
        "seen_boards_affine_minus = generate_board_states(affine_seen_shapes_minus, 1)\n",
        "unseen_boards_affine_minus = generate_board_states(affine_unseen_shapes_minus,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW652UjGphdC"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                 out_channels=num_hiddens//2,\n",
        "                                 kernel_size=4,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv1_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        self._conv_2 = nn.Conv2d(in_channels=num_hiddens//2,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=4,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv2_bn=nn.BatchNorm2d(num_hiddens)\n",
        "        self._conv_3 = nn.Conv2d(in_channels=num_hiddens,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=3,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv3_bn=nn.BatchNorm2d(num_hiddens)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self._conv_1(inputs)\n",
        "        x = F.relu(self.conv1_bn(x))\n",
        "        \n",
        "        x = self._conv_2(x)\n",
        "        x = F.relu(self.conv2_bn(x))\n",
        "        \n",
        "        x = self._conv_3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INoNEr0uphdD"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        \n",
        "        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens, \n",
        "                                                out_channels=num_hiddens//2,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.conv1_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        \n",
        "        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2, \n",
        "                                                out_channels=num_hiddens//2,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.conv2_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        self._conv_trans_3 = nn.ConvTranspose2d(in_channels=num_hiddens//2, \n",
        "                                                out_channels=1,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.m=nn.Sigmoid()\n",
        "    def forward(self, inputs):\n",
        "        x = self._conv_trans_1(inputs)\n",
        "        x = F.relu(self.conv1_bn(x))\n",
        "        x = self._conv_trans_2(x)\n",
        "        x = F.relu(self.conv2_bn(x))\n",
        "        return self.m(self._conv_trans_3(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4vjuCQckkp8"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, num_hiddens, \n",
        "                 num_embeddings, embedding_dim, commitment_cost,codebook_lr=1):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self._encoder = Encoder(1, num_hiddens)\n",
        "        self._decoder = Decoder(embedding_dim,\n",
        "                                num_hiddens)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        z = self._encoder(x)\n",
        "        return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF73FnvkoF5L"
      },
      "source": [
        "batch_size = 32\n",
        "num_training_updates = 5000\n",
        "\n",
        "num_hiddens = 16\n",
        "\n",
        "codebook_lr = 5\n",
        "\n",
        "embedding_dim = 4\n",
        "num_embeddings = 50\n",
        "\n",
        "commitment_cost = 1\n",
        "\n",
        "decay = 0.99\n",
        "\n",
        "learning_rate = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-9N6l_lm5KO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e451aaeb-ebd2-4fcc-86b7-d0665ccdb60e"
      },
      "source": [
        "model2 = Model(num_hiddens,\n",
        "              num_embeddings, embedding_dim, \n",
        "              commitment_cost).to(device)\n",
        "model2=model2.float()\n",
        "model2.eval()\n",
        "state_dict = torch.load('data/ae_affine.pth')\n",
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith('_vq_vae'):\n",
        "        del state_dict[k]\n",
        "model2.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlDgl1aRVsg"
      },
      "source": [
        "shape_map1 = load_shape_map(\"data/images_rotate\")\n",
        "shape_map2 = load_shape_map(\"data/images_affine\")\n",
        "shape_map  = {**shape_map1 ,**shape_map2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KisRYKJnSU9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "def create_datasets(tfs,boards,model,batch_size=18,split=True):\n",
        "  tfs.append(\"out\")\n",
        "  with torch.no_grad():\n",
        "      data=[\n",
        "            (\n",
        "                model(convert_to_image_tensor(one_hot_tensor_represent(i)[0].squeeze(0)).reshape(1,1,64,64).to(device)),\n",
        "                (model(convert_to_image_tensor(one_hot_tensor_represent(lib.apply_program(tfs, i))[0].squeeze(0)).reshape(1,1,64,64).to(device)),\n",
        "                 convert_to_image_tensor(one_hot_tensor_represent(lib.apply_program(tfs, i))[0].squeeze(0)))\n",
        "            )\n",
        "            for i in boards\n",
        "        ]\n",
        "  if not split:\n",
        "    random.shuffle(data)\n",
        "    return data\n",
        "  train_data,test_data=train_test_split(data,test_size=0.1,random_state=19)\n",
        "  train_data,val_data=train_test_split(train_data,test_size=0.1,random_state=21)\n",
        "  train_ds=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size\n",
        "  )\n",
        "  test_ds=test_data\n",
        "  val_ds=torch.utils.data.DataLoader(\n",
        "      val_data,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  return train_ds,test_ds,val_ds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjxsamJNoAZY"
      },
      "source": [
        "def show(img1,img2):\n",
        "    fig = plt.figure(figsize=(20, 7))\n",
        "    for i in range(img1.shape[0]):\n",
        "      fig.add_subplot(2, img1.shape[0], i+1)\n",
        "      plt.imshow(img1[i],cmap='Greys_r')\n",
        "      plt.axis('off')\n",
        "    for i in range(img2.shape[0]):\n",
        "      fig.add_subplot(2, img2.shape[0], i+1+img1.shape[0])\n",
        "      plt.imshow(img2[i],cmap='Greys_r')\n",
        "      plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5ImBNUtoG5b"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self,affine=False):\n",
        "        super(Net, self).__init__()\n",
        "        if not affine:\n",
        "          hidden_layer_size=256\n",
        "        else:\n",
        "          hidden_layer_size=2048\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, hidden_layer_size)\n",
        "        self.fc3 = nn.Linear(hidden_layer_size, 16*8*8)\n",
        "        self.m = nn.Dropout()\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTzxYjobL5x"
      },
      "source": [
        "def evaluate(dataset,net):\n",
        "  total_loss=0\n",
        "  total_acc=0\n",
        "  count=0\n",
        "  for i,data in enumerate(dataset):\n",
        "    inputs,(labels,targets)=data\n",
        "    inputs.to(device)\n",
        "    labels.to(device)\n",
        "    outputs=net(inputs)\n",
        "    labels=labels.reshape(outputs.shape)\n",
        "    criterion=nn.MSELoss()\n",
        "    loss=criterion(outputs,labels)\n",
        "    total_loss+=float(loss)\n",
        "    count+=1\n",
        "  return total_loss/count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Eij-7kt8yy"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def train(net,train_ds,val_ds,optimizer,no_of_epochs=1000,save_file=\"temp.pth\"):\n",
        "  train_losses=[]\n",
        "  eval_losses=[]\n",
        "  min_loss=float('inf')\n",
        "  for epoch in range(no_of_epochs):\n",
        "    total_loss=0\n",
        "    total_acc=0\n",
        "    count=0\n",
        "    for i,data in enumerate(train_ds):\n",
        "      inputs,(labels,_)=data\n",
        "      inputs.to(device)\n",
        "      labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs=net(inputs)\n",
        "      # print(inputs.shape,outputs.shape)\n",
        "      criterion=nn.MSELoss()\n",
        "      labels=labels.reshape(outputs.shape)\n",
        "      # print(outputs.shape,labels.shape)\n",
        "      # output_indices=multihot_to_integer(outputs,50)\n",
        "      # label_indices=multihot_to_integer(labels,50)\n",
        "      # acc=accuracy_score(output_indices.cpu().flatten(),label_indices.cpu().flatten())\n",
        "\n",
        "      loss=criterion(outputs,labels)\n",
        "      loss.backward()\n",
        "      total_loss+=float(loss)\n",
        "      # total_acc+=acc\n",
        "      count+=1\n",
        "      optimizer.step()\n",
        "    #   # data.detach()\n",
        "    # outputs.detach()\n",
        "    train_loss = evaluate(train_ds,net)\n",
        "    eval_loss = evaluate(val_ds,net)\n",
        "    if epoch>0:\n",
        "      train_losses.append(train_loss/count)\n",
        "      eval_losses.append(eval_loss/count)\n",
        "    # if epoch%1000==0:\n",
        "    if eval_loss<min_loss:\n",
        "      min_loss=eval_loss\n",
        "      torch.save(net.state_dict(), save_file)\n",
        "      print('saving best model epoch %d' %(epoch))\n",
        "    print(\"epoch %d total train loss %.6f eval loss %.6f\" %(epoch,train_loss/count,eval_loss/count))\n",
        "  return train_losses,eval_losses\n",
        " \n",
        "        # zeroes the gradient buffers of all parameter\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc8lm4YNaDXV"
      },
      "source": [
        "def ohe_decode1(ohe_repr):\n",
        "        decoded = []\n",
        "        for elem in ohe_repr:\n",
        "            shape_id, x, y = [\n",
        "                i.argmax().item() for i in torch.split(elem, data_split, dim=0)\n",
        "            ]\n",
        "            shape = shapes[shape_id]\n",
        "            decoded.append((shape, (x, y)))\n",
        "        return decoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6sxX8yerh1T"
      },
      "source": [
        "from torchvision import transforms\n",
        "def convert_to_image_tensor(ohe):\n",
        "    board=ohe_decode1([ohe.cpu()])\n",
        "    img=draw_board(board,shape_map)\n",
        "    return transforms.ToTensor()(transforms.functional.to_grayscale(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RrO0q97q2cE"
      },
      "source": [
        "def visualize(test_ds,net,model2):\n",
        "  for i,data in enumerate(test_ds):\n",
        "    inputs=data[0]\n",
        "    inputs,(labels,targets)=data\n",
        "    inputs.to(device)\n",
        "    labels.to(device)\n",
        "    outputs=net(inputs)\n",
        "    output=model2._decoder(outputs.reshape(-1,16,8,8))\n",
        "    input1=model2._decoder(inputs.reshape(-1,16,8,8))\n",
        "    show(input1[5:13,0].detach().cpu(),output[5:13,0].detach().cpu())\n",
        "    break\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMlZT9K2Ko87"
      },
      "source": [
        "def load_net(path,affine=False):\n",
        "  net=Net(affine=affine)\n",
        "  net.load_state_dict(torch.load(path))\n",
        "  net.eval()\n",
        "  net.to(device)\n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOae-Dvrpy9V"
      },
      "source": [
        "import torch.optim as optim\n",
        "def e2e(tf,model,boards,save_dir,learning_rate=1e-3,train_steps=1000,load=False):\n",
        "  train_ds,test_ds,val_ds=create_datasets([tf],boards,model,18)\n",
        "  if load is False:\n",
        "    net = Net(affine=(tf.startswith('affine')))\n",
        "  else:\n",
        "    net = load_net(save_dir+'%s.pth' %(tf))\n",
        "  net.to(device)\n",
        "  optimizer = optim.Adam(net.parameters(), lr=learning_rate, amsgrad=False,weight_decay=1e-5)\n",
        "  train_losses,eval_losses=train(net,train_ds,val_ds,optimizer,train_steps,save_dir+'%s.pth' %(tf))\n",
        "  plt.plot(range(len(train_losses)),train_losses)\n",
        "  plt.plot(range(len(eval_losses)),eval_losses)\n",
        "  plt.show()\n",
        "  visualize(test_ds,net,model)\n",
        "  torch.save(net.state_dict(), save_dir+'%s.pth' %(tf))\n",
        "  return net,train_ds,test_ds,val_ds  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5H8Qz3Tx4kM"
      },
      "source": [
        "def get_first_half(my_list):\n",
        "  return my_list[:len(my_list)//2]\n",
        "def get_second_half(my_list):\n",
        "  return my_list[len(my_list)//2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPk-glwUBbcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "91cf81e4-3abe-4639-9e97-ddaea689dd20"
      },
      "source": [
        "import re\n",
        "net,train_ds,test_ds,val_ds=e2e('shiftdown',model2,seen_boards+seen_boards_affine_minus+seen_boards_affine_plus,save_dir='data/transforms',train_steps=2000,learning_rate=3e-5,load=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving best model epoch 0\n",
            "epoch 0 total train loss 0.001470 eval loss 0.001475\n",
            "saving best model epoch 1\n",
            "epoch 1 total train loss 0.000622 eval loss 0.000623\n",
            "saving best model epoch 2\n",
            "epoch 2 total train loss 0.000598 eval loss 0.000599\n",
            "saving best model epoch 3\n",
            "epoch 3 total train loss 0.000589 eval loss 0.000590\n",
            "saving best model epoch 4\n",
            "epoch 4 total train loss 0.000581 eval loss 0.000582\n",
            "saving best model epoch 5\n",
            "epoch 5 total train loss 0.000570 eval loss 0.000573\n",
            "saving best model epoch 6\n",
            "epoch 6 total train loss 0.000559 eval loss 0.000561\n",
            "saving best model epoch 7\n",
            "epoch 7 total train loss 0.000545 eval loss 0.000548\n",
            "saving best model epoch 8\n",
            "epoch 8 total train loss 0.000530 eval loss 0.000533\n",
            "saving best model epoch 9\n",
            "epoch 9 total train loss 0.000513 eval loss 0.000515\n",
            "saving best model epoch 10\n",
            "epoch 10 total train loss 0.000494 eval loss 0.000496\n",
            "saving best model epoch 11\n",
            "epoch 11 total train loss 0.000476 eval loss 0.000478\n",
            "saving best model epoch 12\n",
            "epoch 12 total train loss 0.000460 eval loss 0.000461\n",
            "saving best model epoch 13\n",
            "epoch 13 total train loss 0.000445 eval loss 0.000446\n",
            "saving best model epoch 14\n",
            "epoch 14 total train loss 0.000431 eval loss 0.000433\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-fe7dd0b43e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me2e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shiftdown'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseen_boards\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mseen_boards_affine_minus\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mseen_boards_affine_plus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/transforms'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-d349740c3791>\u001b[0m in \u001b[0;36me2e\u001b[0;34m(tf, model, boards, save_dir, learning_rate, train_steps, load)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'%s.pth'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-a64df4828698>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_ds, val_ds, optimizer, no_of_epochs, save_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#   # data.detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# outputs.detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-2a80946befa9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, net)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtotal_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}