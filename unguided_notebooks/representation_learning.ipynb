{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FuvN8Ik9wRU",
        "outputId": "9c7c41eb-5764-4bd9-d7ca-a087b8f31ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nar'...\n",
            "remote: Enumerating objects: 9172, done.\u001b[K\n",
            "remote: Counting objects: 100% (9095/9095), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8988/8988), done.\u001b[K\n",
            "remote: Total 9172 (delta 155), reused 9042 (delta 105), pack-reused 77\u001b[K\n",
            "Receiving objects: 100% (9172/9172), 80.35 MiB | 37.66 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://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@github.com/threewisemonkeys-as/nar.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgFgSwHD-3LP",
        "outputId": "e2b3f5c0-f7b1-4d9e-8193-2302b3c90b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nar\n"
          ]
        }
      ],
      "source": [
        "%cd nar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWZM1Xfg_G3B",
        "outputId": "28efe499-1049-4e2d-86c6-e3c1d75d3e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.11.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.62.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.10.0+cu111)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.13)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.3.4)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.70.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 8)) (3.10.0.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 11)) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r requirements.txt (line 11)) (1.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->-r requirements.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->-r requirements.txt (line 6)) (3.7.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=fe3654481e0a9e1a302447243d379389a10e0b0e6f510c01d25cf218a9e45f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=867746d9e558150015d58f3cb6fa8a285315a6948dda24a1ceb3a0418674bb6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.26 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.2 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "cv1QS1Zz-8Qf",
        "outputId": "47fe72b8-7cad-4577-a7c0-7ef2452e3b9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pathlib\n",
        "import dill\n",
        "import torch\n",
        "\n",
        "from src.datagen import (\n",
        "    generate_board_states,\n",
        "    get_seen_unseen_split,\n",
        "    get_image_data\n",
        ")\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from src.image import load_shape_map\n",
        "import pickle\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from src.library import Library,Primitive,AffineTransform,to_shape_creator,shift_creator,flip\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoYUneag_TcW"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "dtype = torch.float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0H2APSw_YLS"
      },
      "outputs": [],
      "source": [
        "data_path=pathlib.Path(\"data/\")\n",
        "lib = dill.load(open(data_path.joinpath(\"libraries/library1.pkl\"), \"rb\"))\n",
        "\n",
        "\n",
        "shapes = [os.path.splitext(p)[0] for p in os.listdir('data/images_rotate')]\n",
        "boards = generate_board_states(shapes, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T56PFwPQGn0H"
      },
      "outputs": [],
      "source": [
        "shape_map1 = load_shape_map(\"data/images_rotate\")\n",
        "shape_map2 = load_shape_map(\"data/images_affine\")\n",
        "shape_map  = {**shape_map1 ,**shape_map2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ddury68jUX0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_rotations(shapes,angles=[0,90,180,270]):\n",
        "  ans=[]\n",
        "  for shape,angle in product(shapes,angles):\n",
        "    ans.append(\"%d%s\" %(angle,shape))\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVUNZXjgUroH"
      },
      "outputs": [],
      "source": [
        "def add_affine(shapes,x,y):\n",
        "  ans=[]\n",
        "  for shape in shapes:\n",
        "    ans.append(shape+str(x)+str(y))\n",
        "  return ans+shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezLci_gb4dYY"
      },
      "outputs": [],
      "source": [
        "def generate_data(shapes,pos,shape_map):\n",
        "  images=get_image_data(shapes,pos,shape_map)\n",
        "  print(len(images))\n",
        "  random.shuffle(images)\n",
        "  data=[transforms.ToTensor()(transforms.functional.to_grayscale(image[0])).unsqueeze_(0) for image in images]\n",
        "  ds=torch.utils.data.DataLoader(\n",
        "    data,\n",
        "    batch_size=batch_size\n",
        "  )\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM9NXhqIW4Fd"
      },
      "outputs": [],
      "source": [
        "affine_x=5\n",
        "affine_y=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYSTWE27LMq_"
      },
      "outputs": [],
      "source": [
        "trans_images = pickle.load(open('data/trans_images.pickle','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LCIzSIXhA25"
      },
      "outputs": [],
      "source": [
        "\n",
        "_,_,seen_pos,unseen_pos=get_seen_unseen_split(shape_map1)\n",
        "unseen_shapes= add_rotations([\"k\",\"w\",\"u\",\"psi\"])\n",
        "seen_shapes = add_rotations([\"circle\", \"square\", \"triangle\", \"delta\", \"b\", \"d\", \"e\", \"g\", \"m\", \"r\", \"s\", \"x\", \"z\", \"theta\", \"pi\", \"tau\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpU071iVVRaD"
      },
      "outputs": [],
      "source": [
        "affine_seen_shapes=[]\n",
        "affine_unseen_shapes=[]\n",
        "for key in trans_images:\n",
        "  if (key[1]==(5,5) or key[1]==(-5,-5)) and key[0] in seen_shapes:\n",
        "    affine_seen_shapes.append(key[0]+str(key[1][0])+str(key[1][1]))\n",
        "  elif (key[1]==(5,5) or key[1]==(-5,-5)) and key[0] in unseen_shapes:\n",
        "    affine_unseen_shapes.append(key[0]+str(key[1][0])+str(key[1][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TEJJb35TZAG"
      },
      "outputs": [],
      "source": [
        "def add_affine(shapes,x,y):\n",
        "  ans=[]\n",
        "  for shape in shapes:\n",
        "    ans.append(shape+str(x)+str(y))\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwkkt0arXFFX",
        "outputId": "627e85a2-037e-4411-bc0e-7fc3a2db9fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "246132\n"
          ]
        }
      ],
      "source": [
        "images_inp=get_image_data(seen_shapes+affine_seen_shapes+affine_unseen_shapes+unseen_shapes,random.sample(seen_pos,int(len(seen_pos)*0.75)),shape_map,noise=False)\n",
        "random.shuffle(images_inp)\n",
        "print(len(images_inp))\n",
        "data=[transforms.ToTensor()(transforms.functional.to_grayscale(image[0])).unsqueeze_(0) for image in images_inp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucy7kCwpXjeB"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data,test_data=train_test_split(data,test_size=0.1)\n",
        "train_data,val_data=train_test_split(train_data,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW652UjGphdC"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                 out_channels=num_hiddens//2,\n",
        "                                 kernel_size=4,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv1_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        self._conv_2 = nn.Conv2d(in_channels=num_hiddens//2,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=4,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv2_bn=nn.BatchNorm2d(num_hiddens)\n",
        "        self._conv_3 = nn.Conv2d(in_channels=num_hiddens,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=3,\n",
        "                                 stride=2, padding=1)\n",
        "        self.conv3_bn=nn.BatchNorm2d(num_hiddens)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self._conv_1(inputs)\n",
        "        x = F.relu(self.conv1_bn(x))\n",
        "        \n",
        "        x = self._conv_2(x)\n",
        "        x = F.relu(self.conv2_bn(x))\n",
        "        \n",
        "        x = self._conv_3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INoNEr0uphdD"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens):\n",
        "        super(Decoder, self).__init__()\n",
        "        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens, \n",
        "                                                out_channels=num_hiddens//2,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.conv1_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        \n",
        "        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2, \n",
        "                                                out_channels=num_hiddens//2,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.conv2_bn=nn.BatchNorm2d(num_hiddens//2)\n",
        "        self._conv_trans_3 = nn.ConvTranspose2d(in_channels=num_hiddens//2, \n",
        "                                                out_channels=1,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        self.m=nn.Sigmoid()\n",
        "    def forward(self, inputs):\n",
        "        x = self._conv_trans_1(inputs)\n",
        "        x = F.relu(self.conv1_bn(x))\n",
        "        x = self._conv_trans_2(x)\n",
        "        x = F.relu(self.conv2_bn(x))\n",
        "        return self.m(self._conv_trans_3(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZmkaw0sphdD"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_training_updates = 5000\n",
        "\n",
        "num_hiddens = 16\n",
        "embedding_dim = 4\n",
        "num_embeddings = 50\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLrqQK-WH2H3"
      },
      "outputs": [],
      "source": [
        "train_ds=DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_ds=DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "val_ds=DataLoader(\n",
        "    val_data,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QQO3Ily-Rne"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, num_hiddens, \n",
        "                 num_embeddings, embedding_dim):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self._encoder = Encoder(1, num_hiddens)\n",
        "        self._decoder = Decoder(embedding_dim,\n",
        "                                num_hiddens)\n",
        "        self.m = nn.Dropout(p=0.3)\n",
        "    def forward(self, x):\n",
        "        \n",
        "        z = self._encoder(x)\n",
        "        x_recon = self._decoder(z)\n",
        "        return  x_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Oei6lsGHgy"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIZdP2DjphdF"
      },
      "outputs": [],
      "source": [
        "model = Model(num_hiddens,\n",
        "              num_embeddings, embedding_dim).to(device)\n",
        "model=model.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdmrbflvJODw",
        "outputId": "9f84e3ec-d627-45a1-a71d-c2353d40074d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 32, 32]             136\n",
            "       BatchNorm2d-2            [-1, 8, 32, 32]              16\n",
            "            Conv2d-3           [-1, 16, 16, 16]           2,064\n",
            "       BatchNorm2d-4           [-1, 16, 16, 16]              32\n",
            "            Conv2d-5             [-1, 16, 8, 8]           2,320\n",
            "           Encoder-6             [-1, 16, 8, 8]               0\n",
            "   ConvTranspose2d-7            [-1, 8, 16, 16]           2,056\n",
            "       BatchNorm2d-8            [-1, 8, 16, 16]              16\n",
            "   ConvTranspose2d-9            [-1, 8, 32, 32]           1,032\n",
            "      BatchNorm2d-10            [-1, 8, 32, 32]              16\n",
            "  ConvTranspose2d-11            [-1, 1, 64, 64]             129\n",
            "          Sigmoid-12            [-1, 1, 64, 64]               0\n",
            "          Decoder-13            [-1, 1, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 7,817\n",
            "Trainable params: 7,817\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.50\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,64, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmnhHNuQmfR1"
      },
      "outputs": [],
      "source": [
        "def get_overall_loss(dataset,model):\n",
        "  total_loss=0\n",
        "  count=0\n",
        "  it=iter(dataset)\n",
        "  while 1:\n",
        "    try:      # Samples the batch\n",
        "        data = next(it)\n",
        "    except StopIteration:\n",
        "        # restart the generator if the previous generator is exhausted.\n",
        "        return total_loss/count\n",
        "    count+=1\n",
        "    input_data=data\n",
        "    output_data=data\n",
        "    input_data = input_data.to(device)\n",
        "    output_data = output_data.to(device)\n",
        "    # convert x from BHW -> BCHW\n",
        "    input_data=input_data.reshape(-1,1,64,64)\n",
        "    output_data=output_data.reshape(-1,1,64,64)\n",
        "    \n",
        "    data_recon = model(input_data.float())\n",
        "    recon_error = F.mse_loss(data_recon.float(), output_data.float())\n",
        "    loss = recon_error\n",
        "    loss.detach()\n",
        "    total_loss+=float(loss)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7jfI978phdF"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate/10, amsgrad=False,)\n",
        "min_loss=float('inf')\n",
        "it=iter(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HwcbtmMzphdF",
        "outputId": "f4312337-ef2d-483b-c8fa-ef895941b2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 iterations\n",
            "recon_error: 0.03516\n",
            "\n",
            "200 iterations\n",
            "recon_error: 0.03046\n",
            "\n",
            "300 iterations\n",
            "recon_error: 0.02654\n",
            "\n",
            "400 iterations\n",
            "recon_error: 0.02334\n",
            "\n",
            "500 iterations\n",
            "recon_error: 0.02072\n",
            "\n",
            "600 iterations\n",
            "recon_error: 0.01850\n",
            "\n",
            "700 iterations\n",
            "recon_error: 0.01661\n",
            "\n",
            "800 iterations\n",
            "recon_error: 0.01508\n",
            "\n",
            "900 iterations\n",
            "recon_error: 0.01372\n",
            "\n",
            "1000 iterations\n",
            "recon_error: 0.01263\n",
            "\n",
            "Saving Best Model\n",
            "1100 iterations\n",
            "recon_error: 0.01159\n",
            "\n",
            "1200 iterations\n",
            "recon_error: 0.01076\n",
            "\n",
            "1300 iterations\n",
            "recon_error: 0.01005\n",
            "\n",
            "1400 iterations\n",
            "recon_error: 0.00937\n",
            "\n",
            "1500 iterations\n",
            "recon_error: 0.00881\n",
            "\n",
            "1600 iterations\n",
            "recon_error: 0.00822\n",
            "\n",
            "1700 iterations\n",
            "recon_error: 0.00783\n",
            "\n",
            "1800 iterations\n",
            "recon_error: 0.00746\n",
            "\n",
            "1900 iterations\n",
            "recon_error: 0.00714\n",
            "\n",
            "2000 iterations\n",
            "recon_error: 0.00677\n",
            "\n",
            "Saving Best Model\n",
            "2100 iterations\n",
            "recon_error: 0.00648\n",
            "\n",
            "2200 iterations\n",
            "recon_error: 0.00620\n",
            "\n",
            "2300 iterations\n",
            "recon_error: 0.00598\n",
            "\n",
            "2400 iterations\n",
            "recon_error: 0.00577\n",
            "\n",
            "2500 iterations\n",
            "recon_error: 0.00552\n",
            "\n",
            "2600 iterations\n",
            "recon_error: 0.00539\n",
            "\n",
            "2700 iterations\n",
            "recon_error: 0.00521\n",
            "\n",
            "2800 iterations\n",
            "recon_error: 0.00502\n",
            "\n",
            "2900 iterations\n",
            "recon_error: 0.00485\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-33721c76c562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_res_recon_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_res_recon_error = []\n",
        "train_res_perplexity = []\n",
        "train_loss=[]\n",
        "for i in range(num_training_updates*4):\n",
        "    try:      # Samples the batch\n",
        "        data = next(it)\n",
        "    except StopIteration:\n",
        "        # restart the generator if the previous generator is exhausted.\n",
        "        it = iter(train_ds)\n",
        "        data =  next(it)\n",
        "    input_data=data\n",
        "    output_data=data\n",
        "    input_data = input_data.to(device)\n",
        "    output_data = output_data.to(device)\n",
        "    \n",
        "    # convert x from BHW -> BCHW\n",
        "    input_data=input_data.reshape(-1,1,64,64)\n",
        "    output_data=output_data.reshape(-1,1,64,64)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    data_recon = model(input_data.float())\n",
        "    recon_error = F.mse_loss(data_recon.float(), output_data.float())\n",
        "    loss = recon_error\n",
        "    loss=loss.float()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_res_recon_error.append(recon_error.item())\n",
        "    train_loss.append(loss.item())\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "        print('%d iterations' % (i+1))\n",
        "        print('recon_error: %.5f' % np.mean(train_res_recon_error[-100:]))\n",
        "        print()\n",
        "\n",
        "    if (i+1) % 1000 == 0:\n",
        "        model.eval()\n",
        "        curr_loss=get_overall_loss(val_ds,model)\n",
        "        model.train()\n",
        "        if  curr_loss < min_loss:\n",
        "          print(\"Saving Best Model\")\n",
        "          min_loss=curr_loss\n",
        "          torch.save(model.state_dict(), 'data/ae_affine.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYcOpV8o4T6R",
        "outputId": "f8c61f13-da2d-400f-f6f5-bebabb53a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ae_affine.pth  images_affine  libraries  transforms\t      weights\n",
            "images\t       images_rotate  programs\t trans_images.pickle\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "representation_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}